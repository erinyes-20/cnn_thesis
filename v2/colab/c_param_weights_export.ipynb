{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fXSvBBZ1o1KYULAFa_HrzpCWyeLVoty-","timestamp":1725459938238}],"authorship_tag":"ABX9TyOkaDwvQxW00Ano27xCxZ2H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dM8PiZpt2dck"},"outputs":[],"source":["import torch\n","import random\n","from torch import nn, save, load\n","from torchvision import datasets\n","import math\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["BATCH_SIZE = 5\n","NUM_CHANNELS = 1\n","IMG_HEIGHT = 28\n","IMG_WIDTH = 28\n","\n","# Load the model.pt file\n","PATH = \"model.pt\"\n","model_params_dict = torch.load(PATH,map_location=torch.device('cpu'))\n","model_params = model_params_dict[\"model_state_dict\"]"],"metadata":{"id":"MFxU02m7aAHV","executionInfo":{"status":"ok","timestamp":1725460941385,"user_tz":-330,"elapsed":19,"user":{"displayName":"Mohammed Mustafa ep20b025","userId":"13151978898129006330"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d387d4f-b2d5-4358-b1bb-f23011e7f4e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-c0a3cec8b3aa>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_params_dict = torch.load(PATH,map_location=torch.device('cpu'))\n"]}]},{"cell_type":"code","source":["model_params.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PQk2TY63qQT","executionInfo":{"status":"ok","timestamp":1725460941385,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohammed Mustafa ep20b025","userId":"13151978898129006330"}},"outputId":"b18a473d-7c03-4c77-db02-0a14f0ba35c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['model.0.weight', 'model.0.bias', 'model.4.weight', 'model.4.bias'])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["model_params['model.0.weight'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4uOnbwr4Esw","executionInfo":{"status":"ok","timestamp":1725460941386,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohammed Mustafa ep20b025","userId":"13151978898129006330"}},"outputId":"ea672395-df8d-43e7-f762-694a3656aac3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 1, 5, 5])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["arch_name = \"bare\"\n","\n","weight_file = open(\"{}_weights.cpp\".format(arch_name), 'w')\n","weight_file.write(\"#include \\\"{}_param_def.h\\\"; \\n\".format(arch_name))\n","weight_file.write(\"typedef float DTYPE; \\n\\n\")\n","\n","param_file = open(\"{}_param_def.h\".format(arch_name), 'w')\n","param_file.write(\"#ifndef PARAM_DEF\\n\")\n","param_file.write(\"#define PARAM_DEF\\n\\n\")\n","\n","# Package the different layers into one c_weights.h by iterating through idc\n","for i,(name, param) in enumerate(model_params.items()):\n","    idx = int(math.floor(i/2 + 1))\n","\n","    if (len(param.shape)==4): # conv params\n","\n","        conv_N, conv_C, conv_H, conv_W = param.shape\n","        param_tensor = param.data\n","\n","        param_file.write(\"\\t #define CONV_{}_WEIGHTS_N {} \\n\".format(idx, conv_N))\n","        param_file.write(\"\\t #define CONV_{}_WEIGHTS_C {} \\n\".format(idx, conv_C))\n","        param_file.write(\"\\t #define CONV_{}_WEIGHTS_H {} \\n\".format(idx, conv_H))\n","        param_file.write(\"\\t #define CONV_{}_WEIGHTS_W {} \\n\\n\".format(idx, conv_W))\n","\n","        weight_file.write(\"\\n DTYPE CONV_{}_WEIGHTS[CONV_{}_WEIGHTS_N * CONV_{}_WEIGHTS_C * CONV_{}_WEIGHTS_H * CONV_{}_WEIGHTS_W] = \\n\".format(idx,idx,idx,idx,idx))\n","\n","        weight_file.write(\"\\n { \\n\") # layer opening brac\n","\n","        for fil_num in range(conv_N):\n","            weight_file.write(\"\\t \\n\") # filter open brac\n","\n","            for kernel_num in range(conv_C):\n","                weight_file.write(\"\\t\\t \\n\")  #kernel opening brac\n","\n","                for kernel_row in range(conv_H):\n","                    for kernel_col in range(conv_W):\n","                        weight_file.write(\"\\t {}, \".format(param[fil_num][kernel_num][kernel_row][kernel_col]))\n","\n","            weight_file.write(\"\\t \\n\") # filter closing brac\n","\n","\n","        weight_file.write(\"\\n }; \\n\") # layer closing brac\n","        prev_flag = \"CONV\"\n","\n","    if (len(param.shape)==2):   # dense param\n","\n","        dense_H, dense_W = param.shape\n","        param_tensor = param.data\n","\n","        param_file.write(\"\\t #define DENSE_{}_WEIGHTS_H {} \\n\".format(idx, dense_H))\n","        param_file.write(\"\\t #define DENSE_{}_WEIGHTS_W {} \\n\\n\".format(idx, dense_W))\n","\n","        weight_file.write(\"\\n DTYPE DENSE_{}_WEIGHTS[DENSE_{}_WEIGHTS_H * DENSE_{}_WEIGHTS_W] = \\n\".format(idx,idx,idx))\n","\n","        weight_file.write(\"\\n { \\n\") # dense opening brac\n","\n","        for dense_row in range(dense_H):\n","            weight_file.write(\"\\n\")\n","            for dense_col in range(dense_W):\n","                weight_file.write(\"\\t {},\".format(param_tensor[dense_row][dense_col]))\n","\n","        weight_file.write(\"\\n }; \\n\") # dense closing brac\n","        prev_flag = \"DENSE\"\n","\n","    if (len(param.shape)==1):   # bias param\n","\n","        bias_L = param.shape[0]\n","        param_tensor = param.data\n","\n","        param_file.write(\"\\t #define {}_{}_BIAS_N {} \\n\\n\".format(prev_flag, idx, bias_L))\n","\n","        weight_file.write(\"\\n DTYPE {}_{}_BIAS[{}_{}_BIAS_N] = \\n\".format(prev_flag, idx, prev_flag, idx))\n","        weight_file.write(\"\\n { \\n\") # opening brac\n","\n","        for i in range(bias_L):\n","            weight_file.write(\"\\t {},\".format(param_tensor[i]))\n","\n","\n","        weight_file.write(\"\\n }; \\n\") # closing brac\n","\n","weight_file.close()\n","\n","param_file.write(\"\\t #define BATCH_SIZE {} \\n\".format(BATCH_SIZE))\n","param_file.write(\"\\t #define NUM_CHANNELS {} \\n\".format(NUM_CHANNELS))\n","param_file.write(\"\\t #define IMG_HEIGHT {} \\n\".format(IMG_HEIGHT))\n","param_file.write(\"\\t #define IMG_WIDTH {} \\n\\n\".format(IMG_WIDTH))\n","\n","param_file.write(\"#endif\")\n","param_file.close()\n"],"metadata":{"id":"pUmaCIZ73DcD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking weight, images, labels distribution to adjust fixed point bit widths\n","# def weight_plot(model_params):\n","#     fig, axes = plt.subplots(int(len(model_params.keys())/2), 2, figsize=(12, 10))\n","#     axes = axes.flatten()\n","\n","#     for i,(name, param) in enumerate(model_params.items()):\n","#         axes[i].hist(param.numpy().flatten(), bins=50, color='blue', edgecolor='black', alpha=0.7)\n","#         axes[i].set_title(f'Distribution of ' + str(name))\n","#         axes[i].set_xlabel('Weight Values')\n","#         axes[i].set_ylabel('Frequency')\n","#         axes[i].grid(True)\n","\n","#     plt.tight_layout()\n","#     plt.show()\n","\n","# weight_plot(model_params)"],"metadata":{"id":"NytwWUIMqVDV"},"execution_count":null,"outputs":[]}]}